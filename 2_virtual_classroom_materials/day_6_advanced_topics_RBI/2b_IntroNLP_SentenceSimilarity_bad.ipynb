{"cells":[{"cell_type":"markdown","source":["## Introduction to Natural Language Processing tasks  \n#### Simple Sentence Similarity"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a9e0cfb0-ae85-47cb-996a-0435a1c1c991"}}},{"cell_type":"markdown","source":["Word embeddings have become widespread in Natural Language Processing. They allow us to easily compute the semantic similarity between two words, or to find the words most similar to a target word. However, in many applications we're more interested in the similarity between two sentences or short texts. In this notebook, I compare some simple ways of computing sentence similarity and investigate how they perform."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"83b8d7ed-2720-4214-a22a-41567c6119d9"}}},{"cell_type":"markdown","source":["### STS Benchmark\n\nThe STS Benchmark brings together the English data from the SemEval sentence similarity tasks between 2012 and 2017. The data is split in training, development and test data: http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2504352f-7877-4b05-8689-ec93b67ad214"}}},{"cell_type":"code","source":["\n!pip install -U -q gensim"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5ea27abe-7a0e-42e8-91be-2ee3a06751d8"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\nimport scipy\nimport math\nimport os\nimport csv\nfrom collections import Counter\n\nos.environ[\"NLTK_DATA\"] = os.path.join(os.getcwd(), 'data', 'nltk_data')\nimport nltk\nfrom nltk.corpus import stopwords\n\nimport gensim\nfrom gensim.models import Word2Vec\nfrom gensim.scripts.glove2word2vec import glove2word2vec\n\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.decomposition import TruncatedSVD\n\nimport tensorflow as tf\nimport tensorflow_hub as hub"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bcf773d2-baa0-435b-975a-991b553b420f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["datapath = os.path.join(os.getcwd(), 'data', 'Stsbenchmark')\n\ndef load_sts_dataset(filename):\n    # Loads a subset of the STS dataset into a DataFrame. In particular both\n    # sentences and their human rated similarity score.\n    sent_pairs = []\n    with tf.io.gfile.GFile(filename, \"r\") as f:\n        for line in f:\n            ts = line.strip().split(\"\\t\")\n            sent_pairs.append((ts[5], ts[6], float(ts[4])))\n    return pd.DataFrame(sent_pairs, columns=[\"sent_1\", \"sent_2\", \"sim\"])\n\nsts_dev = load_sts_dataset(os.path.join(datapath, \"sts-dev.csv\"))\nsts_test = load_sts_dataset(os.path.join(datapath, \"sts-test.csv\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ba8f97b2-cde1-41e5-a8f3-31ef5b1effa1"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["sts_test[:5]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"143c3ad0-f446-4f7a-aebb-3eaee031ac33"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sent_1</th>\n      <th>sent_2</th>\n      <th>sim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A girl is styling her hair.</td>\n      <td>A girl is brushing her hair.</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A group of men play soccer on the beach.</td>\n      <td>A group of boys are playing soccer on the beach.</td>\n      <td>3.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>One woman is measuring another woman's ankle.</td>\n      <td>A woman measures another woman's ankle.</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A man is cutting up a cucumber.</td>\n      <td>A man is slicing a cucumber.</td>\n      <td>4.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A man is playing a harp.</td>\n      <td>A man is playing a keyboard.</td>\n      <td>1.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sent_1</th>\n      <th>sent_2</th>\n      <th>sim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A girl is styling her hair.</td>\n      <td>A girl is brushing her hair.</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A group of men play soccer on the beach.</td>\n      <td>A group of boys are playing soccer on the beach.</td>\n      <td>3.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>One woman is measuring another woman's ankle.</td>\n      <td>A woman measures another woman's ankle.</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A man is cutting up a cucumber.</td>\n      <td>A man is slicing a cucumber.</td>\n      <td>4.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A man is playing a harp.</td>\n      <td>A man is playing a keyboard.</td>\n      <td>1.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### SICK data\n\nThe SICK dataset contains 10,000 English sentence pairs labelled with their semantic relatedness and entailment relation."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1134d42d-6e9e-4c56-a82d-2312f64e3686"}}},{"cell_type":"code","source":["def load_sick(f): \n    datapath = os.path.join(os.getcwd(), 'data', 'SICK')\n    with open(os.path.join(datapath, f)) as s:\n      text = s.read()\n    lines = text.split(\"\\n\")[1:]\n    lines = [l.split(\"\\t\") for l in lines if len(l) > 0]\n    lines = [l for l in lines if len(l) == 5]\n    df = pd.DataFrame(lines, columns=[\"idx\", \"sent_1\", \"sent_2\", \"sim\", \"label\"])\n    df['sim'] = pd.to_numeric(df['sim'])\n    return df\n    \nsick_train = load_sick(\"SICK_train.txt\")\nsick_dev = load_sick(\"SICK_trial.txt\")\nsick_test = load_sick(\"SICK_test_annotated.txt\")\nsick_all = sick_train.append(sick_test).append(sick_dev)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9eb4cf94-98c5-4646-bb7a-e1060bd021e9"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["sick_all[:5]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aebfc200-f2da-4c2f-b258-eba51253ce98"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>idx</th>\n      <th>sent_1</th>\n      <th>sent_2</th>\n      <th>sim</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>A group of kids is playing in a yard and an ol...</td>\n      <td>A group of boys in a yard is playing and a man...</td>\n      <td>4.5</td>\n      <td>NEUTRAL</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>A group of children is playing in the house an...</td>\n      <td>A group of kids is playing in a yard and an ol...</td>\n      <td>3.2</td>\n      <td>NEUTRAL</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>The young boys are playing outdoors and the ma...</td>\n      <td>The kids are playing outdoors near a man with ...</td>\n      <td>4.7</td>\n      <td>ENTAILMENT</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>The kids are playing outdoors near a man with ...</td>\n      <td>A group of kids is playing in a yard and an ol...</td>\n      <td>3.4</td>\n      <td>NEUTRAL</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9</td>\n      <td>The young boys are playing outdoors and the ma...</td>\n      <td>A group of kids is playing in a yard and an ol...</td>\n      <td>3.7</td>\n      <td>NEUTRAL</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>idx</th>\n      <th>sent_1</th>\n      <th>sent_2</th>\n      <th>sim</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>A group of kids is playing in a yard and an ol...</td>\n      <td>A group of boys in a yard is playing and a man...</td>\n      <td>4.5</td>\n      <td>NEUTRAL</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>A group of children is playing in the house an...</td>\n      <td>A group of kids is playing in a yard and an ol...</td>\n      <td>3.2</td>\n      <td>NEUTRAL</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>The young boys are playing outdoors and the ma...</td>\n      <td>The kids are playing outdoors near a man with ...</td>\n      <td>4.7</td>\n      <td>ENTAILMENT</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>The kids are playing outdoors near a man with ...</td>\n      <td>A group of kids is playing in a yard and an ol...</td>\n      <td>3.4</td>\n      <td>NEUTRAL</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9</td>\n      <td>The young boys are playing outdoors and the ma...</td>\n      <td>A group of kids is playing in a yard and an ol...</td>\n      <td>3.7</td>\n      <td>NEUTRAL</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Preparation\n\nFirst we need to do some preparation: some of our models require the sentences to be tokenized, some do not. For that reason we'll make a simple Sentence class where we keep both the raw sentence and the tokenized sentence. The individual methods below will then pick the input they need."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c5ccaf16-c3aa-4b45-9968-0cc14f70c652"}}},{"cell_type":"code","source":["nltk.data.path.append(os.path.join(os.getcwd(), 'data', 'nltk_data'))\nSTOP = set(stopwords.words(\"english\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6d5d97c1-821f-4cf7-81dd-b5693c37e55a"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["class Sentence:\n    def __init__(self, sentence):\n        self.raw = sentence\n        normalized_sentence = sentence.replace(\"‘\", \"'\").replace(\"’\", \"'\")\n        self.tokens = [t.lower() for t in nltk.word_tokenize(normalized_sentence)]\n        self.tokens_without_stop = [t for t in self.tokens if t not in STOP]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cb288ec6-1ba7-42bf-b7ec-22db81fc8e97"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Next, we're going to use the popular [Gensim](https://radimrehurek.com/gensim/) library to load two sets of widely used pre-trained word embeddings: \n[word2vec](https://www.tensorflow.org/tutorials/word2vec) and [GloVe](https://nlp.stanford.edu/projects/glove/)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"447f8817-859a-4cf4-8f4a-ebb0a4e93ca1"}}},{"cell_type":"code","source":["#!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n#https://stackoverflow.com/questions/46433778/import-googlenews-vectors-negative300-bin"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9e5e2a83-c8b1-4614-b78b-1b224f7b1db2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"--2022-08-25 14:14:20--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\r\nResolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.206.77\r\nConnecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.206.77|:443... connected.\r\nHTTP request sent, awaiting response... 403 Forbidden\r\n2022-08-25 14:14:21 ERROR 403: Forbidden.\r\n\r\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["--2022-08-25 14:14:20--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\r\nResolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.206.77\r\nConnecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.206.77|:443... connected.\r\nHTTP request sent, awaiting response... 403 Forbidden\r\n2022-08-25 14:14:21 ERROR 403: Forbidden.\r\n\r\n"]}}],"execution_count":0},{"cell_type":"code","source":["PATH_TO_WORD2VEC = os.path.expanduser(\"~/data/word2vec/GoogleNews-vectors-negative300.bin\")\nPATH_TO_GLOVE = os.path.expanduser(\"~/data/glove/glove.840B.300d.txt\")\n\nword2vec = gensim.models.KeyedVectors.load_word2vec_format(PATH_TO_WORD2VEC, binary=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f6f4979a-b117-49c1-9072-c8b24ebdf604"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)\n\u001B[0;32m<command-4473113267812657>\u001B[0m in \u001B[0;36m<cell line: 4>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mPATH_TO_GLOVE\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexpanduser\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"~/data/glove/glove.840B.300d.txt\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0mword2vec\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgensim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mKeyedVectors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_word2vec_format\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mPATH_TO_WORD2VEC\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbinary\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\n\u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d6ca51ed-0e86-4a68-af69-178e2172b884/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001B[0m in \u001B[0;36mload_word2vec_format\u001B[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001B[0m\n\u001B[1;32m   1721\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1722\u001B[0m         \"\"\"\n\u001B[0;32m-> 1723\u001B[0;31m         return _load_word2vec_format(\n\u001B[0m\u001B[1;32m   1724\u001B[0m             \u001B[0mcls\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfvocab\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfvocab\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbinary\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbinary\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mencoding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mencoding\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0municode_errors\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0municode_errors\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1725\u001B[0m             \u001B[0mlimit\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlimit\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdatatype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdatatype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mno_header\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mno_header\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d6ca51ed-0e86-4a68-af69-178e2172b884/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001B[0m in \u001B[0;36m_load_word2vec_format\u001B[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001B[0m\n\u001B[1;32m   2050\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2051\u001B[0m     \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"loading projection weights from %s\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2052\u001B[0;31m     \u001B[0;32mwith\u001B[0m \u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'rb'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mfin\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2053\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mno_header\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2054\u001B[0m             \u001B[0;31m# deduce both vocab_size & vector_size from 1st pass over file\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/python/lib/python3.9/site-packages/smart_open/smart_open_lib.py\u001B[0m in \u001B[0;36mopen\u001B[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, compression, transport_params)\u001B[0m\n\u001B[1;32m    186\u001B[0m         \u001B[0mtransport_params\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    187\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 188\u001B[0;31m     fobj = _shortcut_open(\n\u001B[0m\u001B[1;32m    189\u001B[0m         \u001B[0muri\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    190\u001B[0m         \u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/python/lib/python3.9/site-packages/smart_open/smart_open_lib.py\u001B[0m in \u001B[0;36m_shortcut_open\u001B[0;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001B[0m\n\u001B[1;32m    359\u001B[0m         \u001B[0mopen_kwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'errors'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0merrors\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    360\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 361\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_builtin_open\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlocal_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbuffering\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbuffering\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mopen_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    362\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    363\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/root/data/word2vec/GoogleNews-vectors-negative300.bin'","errorSummary":"<span class='ansi-red-fg'>FileNotFoundError</span>: [Errno 2] No such file or directory: '/root/data/word2vec/GoogleNews-vectors-negative300.bin'","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)\n\u001B[0;32m<command-4473113267812657>\u001B[0m in \u001B[0;36m<cell line: 4>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mPATH_TO_GLOVE\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexpanduser\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"~/data/glove/glove.840B.300d.txt\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0mword2vec\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgensim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mKeyedVectors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_word2vec_format\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mPATH_TO_WORD2VEC\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbinary\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\n\u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d6ca51ed-0e86-4a68-af69-178e2172b884/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001B[0m in \u001B[0;36mload_word2vec_format\u001B[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001B[0m\n\u001B[1;32m   1721\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1722\u001B[0m         \"\"\"\n\u001B[0;32m-> 1723\u001B[0;31m         return _load_word2vec_format(\n\u001B[0m\u001B[1;32m   1724\u001B[0m             \u001B[0mcls\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfvocab\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfvocab\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbinary\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbinary\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mencoding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mencoding\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0municode_errors\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0municode_errors\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1725\u001B[0m             \u001B[0mlimit\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlimit\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdatatype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdatatype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mno_header\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mno_header\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-d6ca51ed-0e86-4a68-af69-178e2172b884/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001B[0m in \u001B[0;36m_load_word2vec_format\u001B[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001B[0m\n\u001B[1;32m   2050\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2051\u001B[0m     \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"loading projection weights from %s\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2052\u001B[0;31m     \u001B[0;32mwith\u001B[0m \u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'rb'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mfin\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2053\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mno_header\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2054\u001B[0m             \u001B[0;31m# deduce both vocab_size & vector_size from 1st pass over file\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/python/lib/python3.9/site-packages/smart_open/smart_open_lib.py\u001B[0m in \u001B[0;36mopen\u001B[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, compression, transport_params)\u001B[0m\n\u001B[1;32m    186\u001B[0m         \u001B[0mtransport_params\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    187\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 188\u001B[0;31m     fobj = _shortcut_open(\n\u001B[0m\u001B[1;32m    189\u001B[0m         \u001B[0muri\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    190\u001B[0m         \u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/python/lib/python3.9/site-packages/smart_open/smart_open_lib.py\u001B[0m in \u001B[0;36m_shortcut_open\u001B[0;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001B[0m\n\u001B[1;32m    359\u001B[0m         \u001B[0mopen_kwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'errors'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0merrors\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    360\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 361\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_builtin_open\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlocal_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbuffering\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbuffering\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mopen_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    362\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    363\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/root/data/word2vec/GoogleNews-vectors-negative300.bin'"]}}],"execution_count":0},{"cell_type":"markdown","source":["To load Glove, we have to convert the downloaded GloVe file to word2vec format and then load the embeddings into a Gensim model. This will take some time."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7e6a1251-1648-476c-bba0-431dd2a69981"}}},{"cell_type":"code","source":["tmp_file = \"/tmp/glove.840B.300d.w2v.txt\"\nglove2word2vec(PATH_TO_GLOVE, tmp_file)\nglove = gensim.models.KeyedVectors.load_word2vec_format(tmp_file)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"df286d13-1bf4-49fe-9918-8c4a151c08ef"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["Finally, in order to compute weighted averages of word embeddings later, we are going to load a file with word frequencies. These word frequencies have been collected from Wikipedia and saved in a tab-separated file."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"becc5143-b0d6-432e-94c2-a78b37653730"}}},{"cell_type":"code","source":["PATH_TO_FREQUENCIES_FILE = \"data/sentence_similarity/frequencies.tsv\"\nPATH_TO_DOC_FREQUENCIES_FILE = \"data/sentence_similarity/doc_frequencies.tsv\"\n\ndef read_tsv(f):\n    frequencies = {}\n    with open(f) as tsv:\n        tsv_reader = csv.reader(tsv, delimiter=\"\\t\")\n        for row in tsv_reader: \n            frequencies[row[0]] = int(row[1])\n        \n    return frequencies\n        \nfrequencies = read_tsv(PATH_TO_FREQUENCIES_FILE)\ndoc_frequencies = read_tsv(PATH_TO_DOC_FREQUENCIES_FILE)\ndoc_frequencies[\"NUM_DOCS\"] = 1288431\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b73b350c-e914-4b4a-997b-e9b6912587dd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["## Similarity methods"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"66c5480d-daec-4d19-a882-b4c988fcab5e"}}},{"cell_type":"markdown","source":["### Baseline\n\nAs our baseline, we're going for the simplest way of computing sentence embeddings: just take the embeddings of the words in the sentence (minus the stopwords), and compute their average, weighted by the sentence frequency of each word. \n\nWe then use the cosine to calculate the similarity between two sentence embeddings."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fa4059ea-3d12-4bed-9202-cbf97121193b"}}},{"cell_type":"code","source":["def run_avg_benchmark(sentences1, sentences2, model=None, use_stoplist=False, doc_freqs=None): \n\n    if doc_freqs is not None:\n        N = doc_freqs[\"NUM_DOCS\"]\n    \n    sims = []\n    for (sent1, sent2) in zip(sentences1, sentences2):\n    \n        tokens1 = sent1.tokens_without_stop if use_stoplist else sent1.tokens\n        tokens2 = sent2.tokens_without_stop if use_stoplist else sent2.tokens\n\n        tokens1 = [token for token in tokens1 if token in model]\n        tokens2 = [token for token in tokens2 if token in model]\n        \n        if len(tokens1) == 0 or len(tokens2) == 0:\n            sims.append(0)\n            continue\n        \n        tokfreqs1 = Counter(tokens1)\n        tokfreqs2 = Counter(tokens2)\n        \n        weights1 = [tokfreqs1[token] * math.log(N/(doc_freqs.get(token, 0)+1)) \n                    for token in tokfreqs1] if doc_freqs else None\n        weights2 = [tokfreqs2[token] * math.log(N/(doc_freqs.get(token, 0)+1)) \n                    for token in tokfreqs2] if doc_freqs else None\n                \n        embedding1 = np.average([model[token] for token in tokfreqs1], axis=0, weights=weights1).reshape(1, -1)\n        embedding2 = np.average([model[token] for token in tokfreqs2], axis=0, weights=weights2).reshape(1, -1)\n\n        sim = cosine_similarity(embedding1, embedding2)[0][0]\n        sims.append(sim)\n\n    return sims"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"879e5c99-1d29-4763-afee-5eefe00f5aab"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["### Word Mover's Distance\n\nWord mover's distance is a popular alternative to the simple average embedding similarity. The Word Mover's Distance uses the word embeddings of the words in two texts to measure the minimum amount that the words in one text need to \"travel\" in semantic space to reach the words of the other text. Word mover's distance is available in the popular Gensim library."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"df2d2767-ade0-4ee6-bde1-fab8638947e8"}}},{"cell_type":"code","source":["def run_wmd_benchmark(sentences1, sentences2, model, use_stoplist=False):\n    \n    sims = []\n    for (sent1, sent2) in zip(sentences1, sentences2):\n    \n        tokens1 = sent1.tokens_without_stop if use_stoplist else sent1.tokens\n        tokens2 = sent2.tokens_without_stop if use_stoplist else sent2.tokens\n        \n        tokens1 = [token for token in tokens1 if token in model]\n        tokens2 = [token for token in tokens2 if token in model]\n        \n        if len(tokens1) == 0 or len(tokens2) == 0:\n            tokens1 = [token for token in sent1.tokens if token in model]\n            tokens2 = [token for token in sent2.tokens if token in model]\n            \n        sims.append(-model.wmdistance(tokens1, tokens2))\n        \n    return sims"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8d761012-6b45-4204-b5e2-80ced3f81ccb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["### Smooth Inverse Frequency\n\nTaking the average of the word embeddings in a sentence, like we did above, is a very crude method of computing sentence embeddings. Most importantly, this gives far too much weight to words that are quite irrelevant, semantically speaking. Smooth Inverse Frequency tries to solve this problem. \n\nTo compute SIF sentence embeddings, we first compute a weighted average of the token embeddings in the sentence. This procedure is very similar to the weighted average we used above, with the single difference that the word embeddings are weighted by `a/a+p(w)`, where `w` is a parameter that is set to `0.001` by default, and `p(w)` is the estimated relative frequency of a word in a reference corpus."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e8a4e986-cadb-4266-945c-0929ea838c7e"}}},{"cell_type":"markdown","source":["Next, we need to perform common component removal: we compute the principal component of the sentence embeddings we obtained above and subtract from them their projections on this first principal component. This corrects for the influence of high-frequency words that mostly have a syntactic or discourse function, such as \"just\", \"there\", \"but\", etc."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6896bdec-0d1e-414a-be85-655dd8927350"}}},{"cell_type":"code","source":["def remove_first_principal_component(X):\n    svd = TruncatedSVD(n_components=1, n_iter=7, random_state=0)\n    svd.fit(X)\n    pc = svd.components_\n    XX = X - X.dot(pc.transpose()) * pc\n    return XX\n\n\ndef run_sif_benchmark(sentences1, sentences2, model, freqs={}, use_stoplist=False, a=0.001): \n    total_freq = sum(freqs.values())\n    \n    embeddings = []\n    \n    # SIF requires us to first collect all sentence embeddings and then perform \n    # common component analysis.\n    for (sent1, sent2) in zip(sentences1, sentences2): \n        \n        tokens1 = sent1.tokens_without_stop if use_stoplist else sent1.tokens\n        tokens2 = sent2.tokens_without_stop if use_stoplist else sent2.tokens\n        \n        tokens1 = [token for token in tokens1 if token in model]\n        tokens2 = [token for token in tokens2 if token in model]\n        \n        weights1 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens1]\n        weights2 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens2]\n        \n        embedding1 = np.average([model[token] for token in tokens1], axis=0, weights=weights1)\n        embedding2 = np.average([model[token] for token in tokens2], axis=0, weights=weights2)\n        \n        embeddings.append(embedding1)\n        embeddings.append(embedding2)\n        \n    embeddings = remove_first_principal_component(np.array(embeddings))\n    sims = [cosine_similarity(embeddings[idx*2].reshape(1, -1), \n                              embeddings[idx*2+1].reshape(1, -1))[0][0] \n            for idx in range(int(len(embeddings)/2))]\n\n    return sims"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3288e41e-3679-4c5e-9adf-26cacf671c44"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["The methods above share two important characteristics: \n\n- As simple bag-of-word methods, they do take not word order into account.\n- The word embeddings they use have been learned in an unsupervised manner. \n\nBoth these characteristics are potential downsides: \n\n- Since differences in word order can point to differences in meaning (compare `the dog bites the man` with `the man bites the dog`), we'd like our sentence embeddings to be sensitive to this variation.\n- Supervised training can help sentence embeddings learn the meaning of a sentence more directly.\n\nWe can achieve both points by using a pre-trained sentence encoder to produce our sentence embeddings. Several such encoders are available. We'll investigate InferSent and the Google Sentence Encoder."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ab1f431d-08a6-4463-b304-ac56763860bc"}}},{"cell_type":"markdown","source":["### InferSent\n\n[InferSent](https://github.com/facebookresearch/InferSent) is a pre-trained encoder that produces sentence embeddings. \nMore particularly, it is a BiLSTM with max pooling that was trained on the SNLI dataset, 570k English sentence pairs labelled with one of three categories: entailment, contradiction or neutral. InferSent was developed and trained by Facebook Research.\n\nLet's first download the resources we need."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2c4c4f7b-248e-4a8f-bff7-3c4a5b434360"}}},{"cell_type":"code","source":["!wget -nc https://raw.githubusercontent.com/facebookresearch/SentEval/master/examples/models.py\n!wget -nc https://s3.amazonaws.com/senteval/infersent/infersent.allnli.pickle"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"37fbcf32-0ae6-499e-98a4-dc6543575c43"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["Then we load the model."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"87911992-6a7c-4820-afaa-09925ab68110"}}},{"cell_type":"code","source":["import torch\n\ninfersent = torch.load('infersent.allnli.pickle', map_location=lambda storage, loc: storage)\ninfersent.use_cuda = False\ninfersent.set_glove_path(PATH_TO_GLOVE)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9d5b8a7e-643a-4195-9017-85b90bcc3361"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["Finally, we can run the benchmark by having InferSent encode the two sets of sentences and compute the cosine similarity between the corresponding sentences."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cbbdaf23-8546-42c2-8b73-08c29cb20d0b"}}},{"cell_type":"code","source":["def run_inf_benchmark(sentences1, sentences2):\n    \n    raw_sentences1 = [sent1.raw for sent1 in sentences1]\n    raw_sentences2 = [sent2.raw for sent2 in sentences2]\n    \n    infersent.build_vocab(raw_sentences1 + raw_sentences2, tokenize=True)\n    embeddings1 = infersent.encode(raw_sentences1, tokenize=True)\n    embeddings2 = infersent.encode(raw_sentences2, tokenize=True)\n    \n    inf_sims = []\n    for (emb1, emb2) in zip(embeddings1, embeddings2): \n        sim = cosine_similarity(emb1.reshape(1, -1), emb2.reshape(1, -1))[0][0]\n        inf_sims.append(sim)\n\n    return inf_sims   "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"162507b3-6563-4692-a3a1-274063eddcf4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["### Google Sentence Encoder\n\nThe [Google Sentence Encoder](https://www.tensorflow.org/hub/modules/google/universal-sentence-encoder/1) is Google's answer to Facebook's InferSent. It comes in two forms: \n\n- a Transformer model that takes the element-wise sum of the context-aware word representations produced by the encoding subgraph of a Transformer model.\n- a Deep Averaging Network (DAN) where input embeddings for words and bigrams are averaged together and passed through a feed-forward deep neural network.\n\nThe Transformer model tends to give better results, but at the time of writing, only the DAN-based encoder was available.\n\nIn contrast to InferSent, the Google Sentence Encoder was trained on a combination of unsupervised data (in a skip-thought-like task) and supervised data (the SNLI corpus).\n\nThe Google Sentence Encoder can be loaded from the Tensorflow Hub."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dc4b71fd-8618-4373-889b-1fe7357ce0dc"}}},{"cell_type":"code","source":["tf.logging.set_verbosity(tf.logging.ERROR)\nembed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/1\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"35650f4f-e24e-4e17-8725-839c4e378ed4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["Like InferSent above, we'll have the it encode the two sets of sentences and return the similarities between the embeddings it produced."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8311f446-d6d3-469f-86d8-464025901156"}}},{"cell_type":"code","source":["def run_gse_benchmark(sentences1, sentences2):\n    sts_input1 = tf.placeholder(tf.string, shape=(None))\n    sts_input2 = tf.placeholder(tf.string, shape=(None))\n\n    sts_encode1 = tf.nn.l2_normalize(embed(sts_input1))\n    sts_encode2 = tf.nn.l2_normalize(embed(sts_input2))\n        \n    sim_scores = tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), axis=1)\n    \n    with tf.Session() as session:\n        session.run(tf.global_variables_initializer())\n        session.run(tf.tables_initializer())\n      \n        [gse_sims] = session.run(\n            [sim_scores],\n            feed_dict={\n                sts_input1: [sent1.raw for sent1 in sentences1],\n                sts_input2: [sent2.raw for sent2 in sentences2]\n            })\n    return gse_sims\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"41768f44-7587-4ee7-9a79-6d11f132b461"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["## Experiments\n\nFinally, it's time to run the actual experiments."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"26cb0026-070a-4d06-9bd1-4cd35cafd9be"}}},{"cell_type":"code","source":["def run_experiment(df, benchmarks): \n    \n    sentences1 = [Sentence(s) for s in df['sent_1']]\n    sentences2 = [Sentence(s) for s in df['sent_2']]\n    \n    pearson_cors, spearman_cors = [], []\n    for label, method in benchmarks:\n        sims = method(sentences1, sentences2)\n        pearson_correlation = scipy.stats.pearsonr(sims, df['sim'])[0]\n        print(label, pearson_correlation)\n        pearson_cors.append(pearson_correlation)\n        spearman_correlation = scipy.stats.spearmanr(sims, df['sim'])[0]\n        spearman_cors.append(spearman_correlation)\n        \n    return pearson_cors, spearman_cors"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1252dd27-68f9-4388-8124-0ca37f23206d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"code","source":["import functools as ft\n\nbenchmarks = [(\"AVG-W2V\", ft.partial(run_avg_benchmark, model=word2vec, use_stoplist=False)),\n              (\"AVG-W2V-STOP\", ft.partial(run_avg_benchmark, model=word2vec, use_stoplist=True)),\n              (\"AVG-W2V-TFIDF\", ft.partial(run_avg_benchmark, model=word2vec, use_stoplist=False, doc_freqs=doc_frequencies)),\n              (\"AVG-W2V-TFIDF-STOP\", ft.partial(run_avg_benchmark, model=word2vec, use_stoplist=True, doc_freqs=doc_frequencies)),\n              (\"AVG-GLOVE\", ft.partial(run_avg_benchmark, model=glove, use_stoplist=False)),\n              (\"AVG-GLOVE-STOP\", ft.partial(run_avg_benchmark, model=glove, use_stoplist=True)),\n              (\"AVG-GLOVE-TFIDF\", ft.partial(run_avg_benchmark, model=glove, use_stoplist=False, doc_freqs=doc_frequencies)),\n              (\"AVG-GLOVE-TFIDF-STOP\", ft.partial(run_avg_benchmark, model=glove, use_stoplist=True, doc_freqs=doc_frequencies)),\n              (\"WMD-W2V\", ft.partial(run_wmd_benchmark, model=word2vec, use_stoplist=False)), \n              (\"WMD-W2V-STOP\", ft.partial(run_wmd_benchmark, model=word2vec, use_stoplist=True)), \n              (\"WMD-GLOVE\", ft.partial(run_wmd_benchmark, model=glove, use_stoplist=False)), \n              (\"WMD-GLOVE-STOP\", ft.partial(run_wmd_benchmark, model=glove, use_stoplist=True)), \n              (\"SIF-W2V\", ft.partial(run_sif_benchmark, freqs=frequencies, model=word2vec, use_stoplist=False)),\n              (\"SIF-GLOVE\", ft.partial(run_sif_benchmark, freqs=frequencies, model=glove, use_stoplist=False)), \n              (\"INF\", run_inf_benchmark),\n              (\"GSE\", run_gse_benchmark)]\n\npearson_results, spearman_results = {}, {}\npearson_results[\"SICK-DEV\"], spearman_results[\"SICK-DEV\"] = run_experiment(sick_dev, benchmarks)\npearson_results[\"SICK-TEST\"], spearman_results[\"SICK-TEST\"] = run_experiment(sick_test, benchmarks)\npearson_results[\"STS-DEV\"], spearman_results[\"STS-DEV\"] = run_experiment(sts_dev, benchmarks)\npearson_results[\"STS-TEST\"], spearman_results[\"STS-TEST\"] = run_experiment(sts_test, benchmarks)  \n"],"metadata":{"scrolled":true,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a58758bd-ea69-4e1a-bd40-b7a0d755c5ed"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["## Results\n\nLet's take a look at our results. We'll mostly work with Pearson correlation, as is standard in the literature, except where Spearman correlation sheds additional light on our findings."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"031b884d-c8f7-41ae-832d-101ca6116ade"}}},{"cell_type":"code","source":["plt.rcParams['figure.figsize'] = (10,5)\n\npearson_results_df = pd.DataFrame(pearson_results)\npearson_results_df = pearson_results_df.transpose()\npearson_results_df = pearson_results_df.rename(columns={i:b[0] for i, b in enumerate(benchmarks)})\n\nspearman_results_df = pd.DataFrame(spearman_results)\nspearman_results_df = spearman_results_df.transpose()\nspearman_results_df = spearman_results_df.rename(columns={i:b[0] for i, b in enumerate(benchmarks)})\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cca1edb5-0a3b-47f8-a467-e6065dc18454"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["### Baselines\n\n- Simple word2vec embeddings outperform GloVe embeddings.\n- With word2vec, it's unclear whether using a stoplist or tf-idf weighting helps. With STS it sometimes does; with SICK it does not. Simply computing an unweighted average of all word2vec embeddings consistently performs pretty well.\n- With GloVe, using a stoplist looks like a very good idea. Using tf-idf weights does not help, with or without a stoplist."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d3d4f9b9-3501-4fe4-83c7-b8b26db9f55f"}}},{"cell_type":"code","source":["pearson_results_df[[b[0] for b in benchmarks if b[0].startswith(\"AVG\")]].plot(kind=\"bar\").legend(loc=\"lower left\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5f3f37d2-5af2-4954-9836-84174456fb55"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["### Word Mover's Distance\n\nBased on our results, there's little reason to use Word Mover's Distance rather than simple word2vec averages. Only on STS-TEST, and only in combination with a stoplist, does WMD clearly leave the baselines behind."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9006be07-d92c-4672-937a-789709835ba3"}}},{"cell_type":"code","source":["pearson_results_df[[\"AVG-W2V\", \"WMD-W2V\", \"WMD-W2V-STOP\", \"AVG-GLOVE-STOP\", \"WMD-GLOVE\", \"WMD-GLOVE-STOP\"]].plot(kind=\"bar\").legend(loc=\"lower left\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1721bd92-8a64-4617-909c-484c2c4c2da6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["### Smooth Inverse Frequency\n\nSmooth Inverse Frequency is the most consistent performer in our tests. On the SICK data, it does about as well as its baseline competitors, on STS it outranks them by a clear margin. Note there is little difference between SIF with word2vec embeddings and SIF with GloVe embeddings. This is remarkable, given the large differences we observed above. It shows SIF's weighting and common component removal is a very effective alternative to using a stoplist."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b831dc03-50a7-4447-aa6b-c6482292358e"}}},{"cell_type":"code","source":["pearson_results_df[[\"AVG-W2V\", \"AVG-GLOVE-STOP\", \"SIF-W2V\", \"SIF-GLOVE\"]].plot(kind=\"bar\").legend(loc=\"lower left\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"be4188f6-1e88-4acb-b189-dd4ad2eba470"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["### Pretrained encoders\n\nPre-trained encoders have a lot to be said for them. However, our results indicate they are not yet able to capitalize fully on their training regime. Throughout our tests, Google's Sentence Encoder looks like a better choice than InferSent. However, the Pearson correlation coefficient shows very little difference with Smooth Inverse Frequency. The differences in Spearman correlation are more outspoken. This may indicate that the Google Sentence Encoder more often gets the relative ordering of the sentences right, but not necessarily the relative differences between them."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4e49263c-6eb5-4e9c-99e2-43e0b71d7c31"}}},{"cell_type":"code","source":["pearson_results_df[[\"SIF-W2V\", \"INF\", \"GSE\"]].plot(kind=\"bar\").legend(loc=\"lower left\")\nspearman_results_df[[\"SIF-W2V\", \"INF\", \"GSE\"]].plot(kind=\"bar\").legend(loc=\"lower left\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"edde21e0-ba86-40f5-9552-0ba074813fb7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["### Putting it all together"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"29497243-4937-46c6-b701-c7452aae28da"}}},{"cell_type":"code","source":["plt.rcParams['figure.figsize'] = (20,13)\npearson_results_df.plot(kind=\"bar\").legend(loc=\"lower left\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"65036011-0f34-4e68-abe8-af87b682ddac"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["## Conclusions\n\nThese are the most important conclusions:\n\n- When you're computing sentence similarity, word2vec embeddings are a safer choice than GloVe embeddings.\n- Although an unweighted average of the word embeddings in the sentence holds its own as a simple baseline, Smooth Inverse Frequency is usually a stronger alternative.\n- When you can use a pre-trained encoder, pick Google's Sentence Encoder, but remember its performance gain may not be all that spectacular."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2eeae94a-14a8-4f58-945a-94a2fd476f73"}}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.3","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"2b_IntroNLP_SentenceSimilarity_bad","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":4473113267812644}},"nbformat":4,"nbformat_minor":0}
