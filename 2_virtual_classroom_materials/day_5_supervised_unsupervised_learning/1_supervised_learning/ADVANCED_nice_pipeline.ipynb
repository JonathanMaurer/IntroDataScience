{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nice Pipeline\n",
    "\n",
    "here we present a nice example of a pipeline which we can use for training purposes. At first glance, it looks messy and hard to read.  \n",
    "But if you take a moment to understand, you will notice the beauty for sure!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just need to import some transformers which are inside of the pipeline.  \n",
    "This is not a operational code, just an example on longer pipelines.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Dimensionality reduction\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "#Imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#Modeling\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Other\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Take a quick glance\n",
    "Please take a quick look onto the pipeline which is below and come back here.\n",
    "\n",
    "## Step 2: Slow walkthrough\n",
    "Get a **high level view** like this:\n",
    "- look toward the top, there is a *FeatureUnion*, which is really a wrapper for entire feature engineering\n",
    "- look at the bottom, there is a *RandomForestClassifier*, which is our predictive model\n",
    "\n",
    "Now we can go deeper inside of our FeatureUnion, which is our **feature engineering**:\n",
    "- it splits into three parts, depending on which features we are attempting to process\n",
    "    - on top, we have numerical features\n",
    "    - in the middle, we have categorical features\n",
    "    - on the bottom, we have textual features\n",
    "- now zoom out again and realize that this is wrapped under FeatureUnion, which means that these features will be transformed in a parallel way and appended next to each other\n",
    "\n",
    "Only now let's **zoom into one part of our feature engineering**, for example into \"numerical features\", on the top:\n",
    "- inside of it, we right away need ColumnTransformer as we want to specify for which columns certain transformation will be applied by name or by type\n",
    "- now we could already be applying transformers, but remember that ColumnTransformer by default drops all untransformed columns, which would mean that if we want to apply some transformations sequentially we would not be able to\n",
    "\n",
    "Finally, **get used to the indentation** (the whitespacing). Your code editor helps with this. Get used to this by clicking just behind the last visible character on the line where you are. For example go behing the last bracket on the line of *SimpleImputer*. Now if you hit Enter, it will land where a code should continue on the next line it you still want to stay within the element, which is the *Pipeline*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://www.codementor.io/@bruce3557/beautiful-machine-learning-pipeline-with-scikit-learn-uiqapbxuj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = Pipeline(steps=[\n",
    "    (\"features\", FeatureUnion([\n",
    "        (\"numerical_features\",\n",
    "         ColumnTransformer([\n",
    "             (\"numerical\",\n",
    "              Pipeline(steps=[(\n",
    "                  \"impute_stage\",\n",
    "                  SimpleImputer(missing_values=np.nan, strategy=\"median\")\n",
    "              )]),\n",
    "              [\"feature_1\"]\n",
    "             )\n",
    "         ])\n",
    "        ), \n",
    "        (\"categorical_features\",\n",
    "            ColumnTransformer([\n",
    "                (\"country_encoding\",\n",
    "                 Pipeline(steps=[\n",
    "                     (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "                     (\"reduction\", NMF(n_components=8)),\n",
    "                 ]),\n",
    "                 [\"country\"],\n",
    "                ),\n",
    "            ])\n",
    "        ), \n",
    "        (\"text_features\",\n",
    "         ColumnTransformer([\n",
    "             (\"title_vec\",\n",
    "              Pipeline(steps=[\n",
    "                  (\"tfidf\", TfidfVectorizer()),\n",
    "                  (\"reduction\", NMF(n_components=50)),\n",
    "              ]),\n",
    "              \"title\"\n",
    "             )\n",
    "         ])\n",
    "        )\n",
    "    ])\n",
    "    ),\n",
    "    (\"classifiers\", RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would work with the pipeline easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_pipeline.fit(train_data, train_labels.values)\n",
    "#predictions = model_pipeline.predict(predict_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. How to write that?\n",
    "Alright, I now have a feeling that I am comfortable with understanding these, but how do we get to write such thing? The answer is: **from the outside - inwards**. Let's walk through an example, of course you could write things differently.  \n",
    "\n",
    "At first, lay yourself a simple structure which separates your feature engineering (inside of FeatureUnion) and your predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = Pipeline(steps=[\n",
    "    (\"features\", FeatureUnion([#all feature engineering goes here])),\n",
    "    (\"classifiers\", RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, depending on your features, split yourself various parts inside of your feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = Pipeline(steps=[\n",
    "    (\"features\", FeatureUnion([(\"numerical_features\", #numerical transformations), \n",
    "                               (\"categorical_features\", #categorical transformations), \n",
    "                               (\"text_features\", #textual transformations)\n",
    "                              ])\n",
    "    ),\n",
    "    (\"classifiers\", RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you want to put inside a ColumnTransformer as the transformations will be applied only to specific columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = Pipeline(steps=[\n",
    "    (\"features\", FeatureUnion([(\"numerical_features\", ColumnTransformer([#numerical transformations])),\n",
    "                               (\"categorical_features\", ColumnTransformer([#categorical transformations])),\n",
    "                               (\"text_features\", ColumnTransformer([#textual transformations]))\n",
    "                              ])\n",
    "    ),\n",
    "    (\"classifiers\", RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can put Pipeline inside of it, for example, in case you have transformers which need to be sequential (such as numeric scaling and feature selection).  \n",
    "And you just start to put in your individually wrote transformations from before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Reflect\n",
    "Continue with this point only once you went through the pipeline above.  \n",
    "\n",
    "Usually we think that nicely written code costs significantly more effort than code scraped together in whichever way. Now that we went through the composite estimators properly, you know that it might be even simpler in many cases, not to mention robustness.  \n",
    "\n",
    "You are hopefully able to tell apart two things:  \n",
    "- Data preprocessing and wrangling.\n",
    "- Data preparation for ML (Feature Engineering)  \n",
    "\n",
    "Always try to separate these things in your use case (code). That is why we present these topics separatedely. It will be of tremendous help in the longer run to write code in this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
